'use client'

import { useRef, useEffect, useState } from 'react'
import ChatPanel from '@/components/ChatPanel'
import { ModeToggle } from '@/components/ModeToggle'
import { useChat } from '@/hooks/useChat'
import VRMViewer from '@/components/VRMViewer'
import type { VRMViewerRef } from '@/components/VRMViewer'
import type { Emotion } from '@asd-aituber/types'
import { useSimpleUnifiedVoice } from '@/hooks/useUnifiedVoiceSynthesis'
import type { VoicevoxAudioQuery } from '@/lib/voicevox-client'
// Removed direct import to avoid webpack chunk issues
// import { LipSync } from '@/lib/lip-sync'

export default function ChatPage() {
  const { messages, isLoading, sendMessage, mode, changeMode } = useChat()
  const vrmViewerRef = useRef<VRMViewerRef>(null)
  const [currentEmotion, setCurrentEmotion] = useState<Emotion>('neutral')
  const [isSpeaking, setIsSpeaking] = useState(false)
  const [mounted, setMounted] = useState(false)
  // Priority 1: å‡¦ç†æ¸ˆã¿ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸IDã‚’è¿½è·¡ã—ã¦é‡è¤‡éŸ³å£°å†ç”Ÿã‚’é˜²ã
  const [processedMessageIds, setProcessedMessageIds] = useState(new Set<string>())
  const [isInitialized, setIsInitialized] = useState(false) // åˆæœŸåŒ–ãƒ•ãƒ©ã‚°
  // Priority 2: éŸ³å£°ã¨ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ã®åŒæœŸã®ãŸã‚ã®çŠ¶æ…‹å¤‰æ•°
  const [currentAudioQuery, setCurrentAudioQuery] = useState<any>(null)
  const [currentAudio, setCurrentAudio] = useState<HTMLAudioElement | null>(null)
  
  
  // éŸ³å£°åˆæˆæ©Ÿèƒ½ï¼ˆâœ… AudioLipSyncæ–¹å¼ã«æ›´æ–°ï¼‰
  const { speak: speakText, stop: stopSpeech, isSpeaking: isVoiceSpeaking, currentEngine } = useSimpleUnifiedVoice({
    preferredEngine: 'auto', // VOICEVOXãŒåˆ©ç”¨å¯èƒ½ãªã‚‰è‡ªå‹•é¸æŠ
    defaultMode: mode === 'ASD' ? 'asd' : 'nt', // ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ¼ãƒ‰ã¨é€£å‹•
    volume: 0.8,
    // âœ… AudioLipSyncæ–¹å¼: AudioBufferã‚’ç›´æ¥VRMã«æ¸¡ã™
    onAudioBufferReady: (audioBuffer: ArrayBuffer) => {
      console.log('[ChatPage] âœ… AudioBuffer received for AudioLipSync')
      if (vrmViewerRef.current?.playAudioWithLipSync) {
        vrmViewerRef.current.playAudioWithLipSync(audioBuffer)
      }
    }
  })
  
  // ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚µã‚¤ãƒ‰ã§ã®ã¿ãƒã‚¦ãƒ³ãƒˆ
  useEffect(() => {
    setMounted(true)
  }, [])

  // Priority 1: åˆå›ãƒ­ãƒ¼ãƒ‰æ™‚ã«æ—¢å­˜ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¨ã¦å‡¦ç†æ¸ˆã¿ã¨ã—ã¦ãƒãƒ¼ã‚¯
  useEffect(() => {
    if (!isInitialized) {
      console.log('[ChatPage] åˆæœŸåŒ–é–‹å§‹: æ—¢å­˜ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒã‚§ãƒƒã‚¯')
      if (messages.length > 0) {
        console.log('[ChatPage] æ—¢å­˜ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚å‡¦ç†æ¸ˆã¿ã¨ã—ã¦ãƒãƒ¼ã‚¯')
        const existingIds = new Set(messages.map(msg => msg.id))
        setProcessedMessageIds(existingIds)
        console.log(`[ChatPage] å‡¦ç†æ¸ˆã¿ã¨ã—ã¦ãƒãƒ¼ã‚¯ã—ãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°: ${existingIds.size}`)
      } else {
        console.log('[ChatPage] æ—¢å­˜ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯ã‚ã‚Šã¾ã›ã‚“')
      }
      setIsInitialized(true)
      console.log('[ChatPage] åˆæœŸåŒ–å®Œäº†')
    }
  }, [messages, isInitialized])

  // âœ… å¤ã„è¤‡é›‘ãªåŒæœŸå‡¦ç†ã¯å‰Šé™¤ - AudioLipSyncæ–¹å¼ã§ã¯ä¸è¦

  // æœ€æ–°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«åŸºã¥ã„ã¦æ„Ÿæƒ…ã‚’æ¨å®šã¨ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯
  useEffect(() => {
    // åˆæœŸåŒ–ãŒå®Œäº†ã™ã‚‹ã¾ã§å¾…ã¤
    if (!isInitialized) {
      console.log('[ChatPage] åˆæœŸåŒ–ãŒå®Œäº†ã—ã¦ã„ã¾ã›ã‚“ã€‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚')
      return
    }
    
    if (messages.length === 0) return

    const lastMessage = messages[messages.length - 1]
    console.log('[ChatPage] ===== æ–°ã—ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ¤œå‡º =====')
    console.log('[ChatPage] åˆæœŸåŒ–æ¸ˆã¿:', isInitialized)
    console.log('[ChatPage] Role:', lastMessage.role)
    console.log('[ChatPage] Content:', lastMessage.content)
    console.log('[ChatPage] Emotion:', lastMessage.emotion)
    console.log('[ChatPage] Message ID:', lastMessage.id)
    console.log('[ChatPage] å‡¦ç†æ¸ˆã¿IDã®æ•°:', processedMessageIds.size)
    
    // Priority 1: å‡¦ç†æ¸ˆã¿ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒã‚§ãƒƒã‚¯
    if (processedMessageIds.has(lastMessage.id)) {
      console.log('[ChatPage] ã“ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯æ—¢ã«å‡¦ç†æ¸ˆã¿ã§ã™ã€‚éŸ³å£°å†ç”Ÿã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚')
      return
    }
    
    // æ–°ã—ã„ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã©ã†ã‹ã‚’ç¢ºèª
    if (lastMessage.role === 'assistant') {
      console.log('[ChatPage] æ–°ã—ã„ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚éŸ³å£°åˆæˆã‚’é–‹å§‹ã—ã¾ã™ã€‚')
      // assistantãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ„Ÿæƒ…ã‚’åæ˜ 
      if (lastMessage.emotion) {
        setCurrentEmotion(lastMessage.emotion)
      }
      
      // Priority 1: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡¦ç†æ¸ˆã¿ã¨ã—ã¦ãƒãƒ¼ã‚¯
      setProcessedMessageIds(prev => new Set(prev).add(lastMessage.id))
      console.log('[ChatPage] ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸IDã‚’å‡¦ç†æ¸ˆã¿ã¨ã—ã¦ãƒãƒ¼ã‚¯ã—ã¾ã—ãŸ:', lastMessage.id)
      
      // Priority 2: éŸ³å£°åˆæˆã®ã¿ã‚’é–‹å§‹ï¼ˆãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ã¯åˆ¥ã®useEffectã§åŒæœŸå®Ÿè¡Œï¼‰
      const startVoiceSynthesis = async () => {
        console.log('[ChatPage] Priority 2: éŸ³å£°åˆæˆã‚’é–‹å§‹ã—ã¾ã™')
        
        // æ—¢å­˜ã®éŸ³å£°ã‚’åœæ­¢
        stopSpeech()
        
        // è¡¨æƒ…ã‚’è¨­å®š
        setIsSpeaking(true)
        
        // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå‡¦ç†: 5ç§’ä»¥å†…ã«ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿ãŒæ¥ãªã‘ã‚Œã°ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        const fallbackTimeout = setTimeout(() => {
          console.warn('[ChatPage] VOICEVOX ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã€‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™')
          if (vrmViewerRef.current) {
            vrmViewerRef.current.speakText(lastMessage.content, () => {
              console.log('[ChatPage] ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯å®Œäº†')
              setIsSpeaking(false)
            })
          }
        }, 5000)
        
        // éŸ³å£°åˆæˆã‚’å®Ÿè¡Œï¼ˆã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿ã¨éŸ³å£°è¦ç´ ã‚’å—ã‘å–ã‚‹ï¼‰
        try {
          await speakText(lastMessage.content, {
            emotion: lastMessage.emotion || 'neutral',
            mode: mode === 'ASD' ? 'asd' : 'nt',
            callbacks: {
              onStart: () => {
                console.log('[ChatPage] Voice synthesis started')
                clearTimeout(fallbackTimeout) // æˆåŠŸã—ãŸã‚‰ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’ã‚¯ãƒªã‚¢
              },
              onEnd: () => {
                console.log('[ChatPage] Voice synthesis ended')
                clearTimeout(fallbackTimeout)
                setIsSpeaking(false)
                // è©±ã—çµ‚ã‚ã£ãŸã‚‰3ç§’å¾Œã«è¡¨æƒ…ã‚’neutralã«æˆ»ã™
                setTimeout(() => {
                  if (vrmViewerRef.current) {
                    vrmViewerRef.current.setEmotion('neutral')
                    setCurrentEmotion('neutral')
                  }
                }, 3000)
              },
              onError: (error) => {
                console.error('[ChatPage] Speech synthesis error:', error)
                clearTimeout(fallbackTimeout)
                setIsSpeaking(false)
                // ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ
                if (vrmViewerRef.current) {
                  vrmViewerRef.current.speakText(lastMessage.content, () => {
                    console.log('[ChatPage] ã‚¨ãƒ©ãƒ¼æ™‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯å®Œäº†')
                    setIsSpeaking(false)
                  })
                }
              }
            }
          })
        } catch (error) {
          console.error('[ChatPage] Voice synthesis failed:', error)
          clearTimeout(fallbackTimeout)
          setIsSpeaking(false)
          // ä¾‹å¤–æ™‚ã‚‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ
          if (vrmViewerRef.current) {
            vrmViewerRef.current.speakText(lastMessage.content, () => {
              console.log('[ChatPage] ä¾‹å¤–æ™‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯å®Œäº†')
              setIsSpeaking(false)
            })
          }
        }
      }
      
      // éŸ³å£°åˆæˆã‚’é–‹å§‹
      startVoiceSynthesis()
    } else {
      console.log('[ChatPage] Not an assistant message, skipping voice synthesis')
    }
  }, [messages, processedMessageIds, isInitialized])


  // ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°çŠ¶æ…‹ã«åŸºã¥ã„ã¦è¡¨æƒ…ã‚’æ›´æ–°
  useEffect(() => {
    if (isLoading) {
      setCurrentEmotion('neutral')
      setIsSpeaking(false)
      // é€²è¡Œä¸­ã®éŸ³å£°åˆæˆã‚’åœæ­¢
      stopSpeech()
      // é€²è¡Œä¸­ã®ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ã‚’åœæ­¢
      if (vrmViewerRef.current) {
        vrmViewerRef.current.stopSpeaking()
      }
    }
  }, [isLoading, stopSpeech])

  return (
    <div className="flex h-screen">
      {/* VRMè¡¨ç¤ºã‚¨ãƒªã‚¢ */}
      <div className="flex-1 relative">
        {mounted ? (
          <VRMViewer 
            ref={vrmViewerRef}
            modelUrl="/models/MyAvatar01_20241125134913.vrm"
            emotion={currentEmotion}
            isSpeaking={isSpeaking}
          />
        ) : (
          <div className="flex items-center justify-center h-full">
            <div>Loading VRM Viewer...</div>
          </div>
        )}
      </div>
      
      {/* ãƒãƒ£ãƒƒãƒˆã‚¨ãƒªã‚¢ - VRMã¨åŒã˜é«˜ã•ã«å›ºå®š */}
      <div className="w-96 bg-gray-100 h-screen flex flex-col">
        {/* ãƒ˜ãƒƒãƒ€ãƒ¼ */}
        <div className="p-4 border-b bg-white shrink-0">
          <h2 className="text-xl font-bold">ASD-AITuber Chat</h2>
          <div className="text-sm text-gray-500 mt-1">
            Mode: {mode} | Emotion: {currentEmotion}
            {(isSpeaking || isVoiceSpeaking) && ` | ğŸ”Š Speaking (${currentEngine})`}
          </div>
        </div>
        
        {/* ãƒ¢ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆ */}
        <div className="p-4 bg-white border-b shrink-0">
          <ModeToggle 
            currentMode={mode}
            onModeChange={changeMode}
          />
        </div>
        
        {/* ãƒãƒ£ãƒƒãƒˆãƒ‘ãƒãƒ« - æ®‹ã‚Šã®é«˜ã•ã‚’ä½¿ç”¨ */}
        <div className="flex-1 min-h-0 bg-white">
          <ChatPanel 
            messages={messages} 
            onSendMessage={sendMessage}
            isLoading={isLoading}
          />
        </div>
      </div>
    </div>
  )
}