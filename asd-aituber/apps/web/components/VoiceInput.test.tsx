import { describe, it, expect, beforeEach, vi } from 'vitest'
import { render, screen, fireEvent, waitFor } from '@testing-library/react'
import VoiceInput from './VoiceInput'

// useSpeechRecognition ãƒ•ãƒƒã‚¯ã®ãƒ¢ãƒƒã‚¯
vi.mock('@/hooks/useSpeechRecognition', () => ({
  useSpeechRecognition: vi.fn()
}))

import { useSpeechRecognition } from '@/hooks/useSpeechRecognition'

const mockUseSpeechRecognition = useSpeechRecognition as any

describe('VoiceInput', () => {
  const mockOnTranscript = vi.fn()

  const defaultMockReturn = {
    isSupported: true,
    isListening: false,
    isInitializing: false,
    hasPermission: true,
    transcript: '',
    interimTranscript: '',
    confidence: 0,
    error: null,
    startListening: vi.fn(),
    stopListening: vi.fn(),
    toggleListening: vi.fn(),
    requestPermission: vi.fn(),
    clearError: vi.fn(),
    clearTranscript: vi.fn(),
    browserInfo: {
      isSupported: true,
      browserName: 'Chrome'
    }
  }

  beforeEach(() => {
    vi.clearAllMocks()
    mockUseSpeechRecognition.mockReturnValue(defaultMockReturn)
  })

  describe('åŸºæœ¬çš„ãªè¡¨ç¤º', () => {
    it('æ­£å¸¸ãªçŠ¶æ…‹ã§é©åˆ‡ã«ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã•ã‚Œã‚‹', () => {
      render(<VoiceInput onTranscript={mockOnTranscript} />)
      
      expect(screen.getByRole('button')).toBeInTheDocument()
      expect(screen.getByText('ãƒã‚¤ã‚¯ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦è©±ã—ã¦ãã ã•ã„...')).toBeInTheDocument()
      expect(screen.getByText('æº–å‚™å®Œäº†')).toBeInTheDocument()
    })

    it('ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ãŒè¡¨ç¤ºã•ã‚Œã‚‹', () => {
      render(
        <VoiceInput 
          onTranscript={mockOnTranscript} 
          placeholder="ã‚«ã‚¹ã‚¿ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸"
        />
      )
      
      expect(screen.getByText('ã‚«ã‚¹ã‚¿ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸')).toBeInTheDocument()
    })

    it('disabledçŠ¶æ…‹ã§ãƒœã‚¿ãƒ³ãŒç„¡åŠ¹ã«ãªã‚‹', () => {
      render(<VoiceInput onTranscript={mockOnTranscript} isDisabled={true} />)
      
      const button = screen.getByRole('button')
      expect(button).toBeDisabled()
    })

    // âœ… Task 1.1.1: VoiceInput disabled propã®ãƒ†ã‚¹ãƒˆä½œæˆ
    it('disabled propãŒtrueã®å ´åˆã€ãƒã‚¤ã‚¯ãƒœã‚¿ãƒ³ãŒç„¡åŠ¹åŒ–ã•ã‚Œã‚‹', () => {
      render(<VoiceInput onTranscript={mockOnTranscript} isDisabled={true} />)
      const button = screen.getByRole('button')
      expect(button).toBeDisabled()
    })

    // âŒ Task 1.1.3: VoiceInputçŠ¶æ…‹å¤‰åŒ–é€šçŸ¥ã®ãƒ†ã‚¹ãƒˆä½œæˆ
    it('éŸ³å£°èªè­˜çŠ¶æ…‹ãŒå¤‰åŒ–ã—ãŸæ™‚ã«onStateChangeãŒå‘¼ã°ã‚Œã‚‹', async () => {
      const mockStartListening = vi.fn().mockResolvedValue(true)  // æˆåŠŸã‚’è¿”ã™ã‚ˆã†ã«ãƒ¢ãƒƒã‚¯
      const onStateChange = vi.fn()
      
      mockUseSpeechRecognition.mockReturnValue({
        ...defaultMockReturn,
        startListening: mockStartListening
      })
      
      const { getByRole } = render(<VoiceInput onTranscript={mockOnTranscript} onStateChange={onStateChange} />)
      
      fireEvent.click(getByRole('button'))
      
      // asyncå‡¦ç†ãŒå®Œäº†ã™ã‚‹ã¾ã§å¾…æ©Ÿ
      await waitFor(() => {
        expect(onStateChange).toHaveBeenCalledWith(true)
      })
    })

    // âŒ æ–°è¦ãƒ†ã‚¹ãƒˆ: disabled propå¤‰æ›´æ™‚ã®éŸ³å£°èªè­˜è‡ªå‹•åœæ­¢
    it('disabled=trueã«ãªã£ãŸæ™‚ã€é€²è¡Œä¸­ã®éŸ³å£°èªè­˜ãŒè‡ªå‹•åœæ­¢ã•ã‚Œã‚‹', async () => {
      const mockStopListening = vi.fn()
      const mockStartListening = vi.fn().mockResolvedValue(true)
      const onStateChange = vi.fn()
      
      mockUseSpeechRecognition.mockReturnValue({
        ...defaultMockReturn,
        isListening: true,  // éŸ³å£°èªè­˜ãŒé€²è¡Œä¸­
        startListening: mockStartListening,
        stopListening: mockStopListening
      })
      
      const { rerender } = render(
        <VoiceInput 
          onTranscript={mockOnTranscript} 
          disabled={false}
          onStateChange={onStateChange}
        />
      )
      
      // disabled=trueã«å¤‰æ›´
      rerender(
        <VoiceInput 
          onTranscript={mockOnTranscript} 
          isDisabled={true}
          onStateChange={onStateChange}
        />
      )
      
      // éŸ³å£°èªè­˜ãŒè‡ªå‹•åœæ­¢ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
      await waitFor(() => {
        expect(mockStopListening).toHaveBeenCalled()
        expect(onStateChange).toHaveBeenCalledWith(false)
      })
    })

    // âŒ æ–°è¦ãƒ†ã‚¹ãƒˆ: disabled=falseæ™‚ã®éŸ³å£°èªè­˜è‡ªå‹•å†é–‹
    it('disabled=falseã«ãªã£ãŸæ™‚ã€å‰å›èã„ã¦ã„ãŸå ´åˆã¯éŸ³å£°èªè­˜ãŒè‡ªå‹•å†é–‹ã•ã‚Œã‚‹', async () => {
      const mockStopListening = vi.fn()
      const mockStartListening = vi.fn().mockResolvedValue(true)
      const onStateChange = vi.fn()
      
      // æœ€åˆã¯éŸ³å£°èªè­˜ä¸­
      mockUseSpeechRecognition.mockReturnValue({
        ...defaultMockReturn,
        isListening: true,
        startListening: mockStartListening,
        stopListening: mockStopListening
      })
      
      const { rerender } = render(
        <VoiceInput 
          onTranscript={mockOnTranscript} 
          isDisabled={false}
          onStateChange={onStateChange}
        />
      )
      
      // disabled=trueã«å¤‰æ›´ï¼ˆéŸ³å£°åˆæˆé–‹å§‹ï¼‰
      rerender(
        <VoiceInput 
          onTranscript={mockOnTranscript} 
          isDisabled={true}
          onStateChange={onStateChange}
        />
      )
      
      // éŸ³å£°èªè­˜åœæ­¢ã‚’ç¢ºèª
      await waitFor(() => {
        expect(mockStopListening).toHaveBeenCalled()
      })
      
      // éŸ³å£°èªè­˜ãŒåœæ­¢çŠ¶æ…‹ã«ãªã£ãŸã“ã¨ã‚’ãƒ¢ãƒƒã‚¯
      mockUseSpeechRecognition.mockReturnValue({
        ...defaultMockReturn,
        isListening: false,  // åœæ­¢çŠ¶æ…‹
        startListening: mockStartListening,
        stopListening: mockStopListening
      })
      
      // disabled=falseã«å¤‰æ›´ï¼ˆéŸ³å£°åˆæˆçµ‚äº†ï¼‰
      rerender(
        <VoiceInput 
          onTranscript={mockOnTranscript} 
          disabled={false}
          onStateChange={onStateChange}
        />
      )
      
      // éŸ³å£°èªè­˜ãŒè‡ªå‹•å†é–‹ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
      await waitFor(() => {
        expect(mockStartListening).toHaveBeenCalled()  // è‡ªå‹•å†é–‹ã•ã‚ŒãŸ
        expect(onStateChange).toHaveBeenCalledWith(true)
      })
    })
  })

  describe('éŸ³å£°èªè­˜ãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„å ´åˆ', () => {
    it('ã‚µãƒãƒ¼ãƒˆå¤–ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¡¨ç¤ºã•ã‚Œã‚‹', () => {
      mockUseSpeechRecognition.mockReturnValue({
        ...defaultMockReturn,
        isSupported: false,
        browserInfo: {
          isSupported: false,
          browserName: 'Firefox',
          recommendedMessage: 'Chromeã€Edgeã€ã¾ãŸã¯Safariã‚’ãŠä½¿ã„ãã ã•ã„ã€‚'
        }
      })
      
      render(<VoiceInput onTranscript={mockOnTranscript} />)
      
      expect(screen.getByText('éŸ³å£°å…¥åŠ›ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“')).toBeInTheDocument()
      expect(screen.getByText('Chromeã€Edgeã€ã¾ãŸã¯Safariã‚’ãŠä½¿ã„ãã ã•ã„ã€‚')).toBeInTheDocument()
    })
  })

  describe('åˆæœŸåŒ–ä¸­ã®è¡¨ç¤º', () => {
    it('åˆæœŸåŒ–ä¸­ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¡¨ç¤ºã•ã‚Œã‚‹', () => {
      mockUseSpeechRecognition.mockReturnValue({
        ...defaultMockReturn,
        isInitializing: true
      })
      
      render(<VoiceInput onTranscript={mockOnTranscript} />)
      
      expect(screen.getByText('éŸ³å£°èªè­˜ã‚’åˆæœŸåŒ–ä¸­...')).toBeInTheDocument()
    })
  })

  describe('æ¨©é™è¦æ±‚', () => {
    it('æ¨©é™ãŒãªã„å ´åˆã«æ¨©é™è¦æ±‚ç”»é¢ãŒè¡¨ç¤ºã•ã‚Œã‚‹', () => {
      mockUseSpeechRecognition.mockReturnValue({
        ...defaultMockReturn,
        hasPermission: false
      })
      
      render(<VoiceInput onTranscript={mockOnTranscript} />)
      
      expect(screen.getByText('ãƒã‚¤ã‚¯ãƒ­ãƒ•ã‚©ãƒ³ã®æ¨©é™ãŒå¿…è¦ã§ã™')).toBeInTheDocument()
      expect(screen.getByText('æ¨©é™ã‚’è¨±å¯')).toBeInTheDocument()
    })

    it('æ¨©é™è¨±å¯ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨æ¨©é™è¦æ±‚ã•ã‚Œã‚‹', async () => {
      const mockRequestPermission = vi.fn().mockResolvedValue(true)
      
      mockUseSpeechRecognition.mockReturnValue({
        ...defaultMockReturn,
        hasPermission: false,
        requestPermission: mockRequestPermission
      })
      
      render(<VoiceInput onTranscript={mockOnTranscript} />)
      
      const permissionButton = screen.getByText('æ¨©é™ã‚’è¨±å¯')
      fireEvent.click(permissionButton)
      
      expect(mockRequestPermission).toHaveBeenCalled()
    })
  })

  describe('ã‚¨ãƒ©ãƒ¼è¡¨ç¤º', () => {
    it('ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã«ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¡¨ç¤ºã•ã‚Œã‚‹', () => {
      mockUseSpeechRecognition.mockReturnValue({
        ...defaultMockReturn,
        error: 'ãƒã‚¤ã‚¯ãƒ­ãƒ•ã‚©ãƒ³ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“'
      })
      
      render(<VoiceInput onTranscript={mockOnTranscript} />)
      
      expect(screen.getByText('ãƒã‚¤ã‚¯ãƒ­ãƒ•ã‚©ãƒ³ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“')).toBeInTheDocument()
    })

    it('ã‚¨ãƒ©ãƒ¼ã®é–‰ã˜ã‚‹ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨ã‚¨ãƒ©ãƒ¼ãŒã‚¯ãƒªã‚¢ã•ã‚Œã‚‹', () => {
      const mockClearError = vi.fn()
      
      mockUseSpeechRecognition.mockReturnValue({
        ...defaultMockReturn,
        error: 'ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸',
        clearError: mockClearError
      })
      
      render(<VoiceInput onTranscript={mockOnTranscript} />)
      
      const closeButton = screen.getByText('âœ•')
      fireEvent.click(closeButton)
      
      expect(mockClearError).toHaveBeenCalled()
    })
  })

  describe('éŸ³å£°èªè­˜ã®åˆ¶å¾¡', () => {
    it('ãƒã‚¤ã‚¯ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨éŸ³å£°èªè­˜ãŒé–‹å§‹ã•ã‚Œã‚‹', async () => {
      const mockToggleListening = vi.fn().mockResolvedValue(true)
      
      mockUseSpeechRecognition.mockReturnValue({
        ...defaultMockReturn,
        toggleListening: mockToggleListening
      })
      
      render(<VoiceInput onTranscript={mockOnTranscript} />)
      
      const micButton = screen.getByRole('button')
      fireEvent.click(micButton)
      
      expect(mockToggleListening).toHaveBeenCalled()
    })

    it('éŒ²éŸ³ä¸­ã¯åœæ­¢ãƒœã‚¿ãƒ³ãŒè¡¨ç¤ºã•ã‚Œã‚‹', () => {
      mockUseSpeechRecognition.mockReturnValue({
        ...defaultMockReturn,
        isListening: true
      })
      
      render(<VoiceInput onTranscript={mockOnTranscript} />)
      
      expect(screen.getByText('â¹ï¸')).toBeInTheDocument()
      expect(screen.getByText('éŒ²éŸ³ä¸­')).toBeInTheDocument()
      expect(screen.getByText('ğŸµ èã„ã¦ã„ã¾ã™...')).toBeInTheDocument()
    })

    it('éŒ²éŸ³ã—ã¦ã„ãªã„æ™‚ã¯ãƒã‚¤ã‚¯ãƒœã‚¿ãƒ³ãŒè¡¨ç¤ºã•ã‚Œã‚‹', () => {
      render(<VoiceInput onTranscript={mockOnTranscript} />)
      
      expect(screen.getByText('ğŸ¤')).toBeInTheDocument()
    })
  })

  describe('ä¸­é–“çµæœã®è¡¨ç¤º', () => {
    it('ä¸­é–“çµæœãŒè¡¨ç¤ºã•ã‚Œã‚‹', () => {
      mockUseSpeechRecognition.mockReturnValue({
        ...defaultMockReturn,
        isListening: true,
        interimTranscript: 'ã“ã‚“ã«ã¡'
      })
      
      render(<VoiceInput onTranscript={mockOnTranscript} />)
      
      expect(screen.getByText('"ã“ã‚“ã«ã¡"')).toBeInTheDocument()
    })

    it('ä¿¡é ¼åº¦ãŒè¡¨ç¤ºã•ã‚Œã‚‹', () => {
      mockUseSpeechRecognition.mockReturnValue({
        ...defaultMockReturn,
        isListening: true,
        confidence: 0.85
      })
      
      render(<VoiceInput onTranscript={mockOnTranscript} />)
      
      expect(screen.getByText('ä¿¡é ¼åº¦:')).toBeInTheDocument()
      expect(screen.getByText('85%')).toBeInTheDocument()
    })
  })

  describe('ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†', () => {
    it('æœ€çµ‚çµæœãŒå¾—ã‚‰ã‚ŒãŸæ™‚ã«onTranscriptãŒå‘¼ã°ã‚Œã‚‹', () => {
      // onFinalResult ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
      let onFinalResultCallback: ((transcript: string, confidence: number) => void) | undefined
      
      mockUseSpeechRecognition.mockImplementation((options) => {
        onFinalResultCallback = options?.onFinalResult
        return defaultMockReturn
      })
      
      render(<VoiceInput onTranscript={mockOnTranscript} />)
      
      // ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
      expect(onFinalResultCallback).toBeDefined()
      
      // æœ€çµ‚çµæœã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
      onFinalResultCallback?.('ã“ã‚“ã«ã¡ã¯', 0.9)
      
      expect(mockOnTranscript).toHaveBeenCalledWith('ã“ã‚“ã«ã¡ã¯')
    })

    it('ç©ºã®æ–‡å­—åˆ—ã§ã¯ onTranscript ãŒå‘¼ã°ã‚Œãªã„', () => {
      let onFinalResultCallback: ((transcript: string, confidence: number) => void) | undefined
      
      mockUseSpeechRecognition.mockImplementation((options) => {
        onFinalResultCallback = options?.onFinalResult
        return defaultMockReturn
      })
      
      render(<VoiceInput onTranscript={mockOnTranscript} />)
      
      // ç©ºã®çµæœã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
      onFinalResultCallback?.('   ', 0.9)
      
      expect(mockOnTranscript).not.toHaveBeenCalled()
    })

    it('ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ä¸­ã¯ onTranscript ãŒå‘¼ã°ã‚Œãªã„', () => {
      let onFinalResultCallback: ((transcript: string, confidence: number) => void) | undefined
      
      mockUseSpeechRecognition.mockImplementation((options) => {
        onFinalResultCallback = options?.onFinalResult
        return defaultMockReturn
      })
      
      render(<VoiceInput onTranscript={mockOnTranscript} isDisabled={true} />)
      
      // çµæœã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
      onFinalResultCallback?.('ã“ã‚“ã«ã¡ã¯', 0.9)
      
      expect(mockOnTranscript).not.toHaveBeenCalled()
    })
  })

  describe('ãƒ’ãƒ³ãƒˆè¡¨ç¤º', () => {
    it('ä½¿ç”¨æ–¹æ³•ã®ãƒ’ãƒ³ãƒˆãŒé©åˆ‡ã«è¡¨ç¤ºã•ã‚Œã‚‹', () => {
      render(<VoiceInput onTranscript={mockOnTranscript} />)
      
      expect(screen.getByText(/ãƒã‚¤ã‚¯ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦è©±ã™ã¨ã€éŸ³å£°ãŒæ–‡å­—ã«å¤‰æ›ã•ã‚Œã¾ã™/)).toBeInTheDocument()
    })

    it('éŒ²éŸ³ä¸­ã‚„ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ’ãƒ³ãƒˆãŒè¡¨ç¤ºã•ã‚Œãªã„', () => {
      mockUseSpeechRecognition.mockReturnValue({
        ...defaultMockReturn,
        isListening: true
      })
      
      render(<VoiceInput onTranscript={mockOnTranscript} />)
      
      expect(screen.queryByText(/ãƒã‚¤ã‚¯ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦è©±ã™ã¨/)).not.toBeInTheDocument()
    })
  })
})